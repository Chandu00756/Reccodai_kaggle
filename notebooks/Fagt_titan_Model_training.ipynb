{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# TITAN-FAGT V4.3: STABLE MAC TRAINING (CLEAN UI + NO FREEZES)\n",
    "# ==================================================================================\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm  # Standard TQDM\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    print(\"CRITICAL: 'timm' library not found. Please run: pip install timm\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "class CFG:\n",
    "    BASE_DIR = '/Users/chanduchitikam/recodai/recodai-luc-scientific-image-forgery-detection'\n",
    "    TRAIN_IMG_PATH = os.path.join(BASE_DIR, 'train_images') \n",
    "    TRAIN_MASK_PATH = os.path.join(BASE_DIR, 'train_masks')\n",
    "    WEIGHTS_NAME = \"TITAN_FAGT_V4_FINAL.pth\"\n",
    "    \n",
    "    seed = 42\n",
    "    img_size = 384\n",
    "    batch_size = 2        # Safe for Mac\n",
    "    accum_iter = 8        # Effective Batch = 16\n",
    "    epochs = 7\n",
    "    lr = 2e-5             \n",
    "    \n",
    "    device = torch.device(\"mps\") \n",
    "    model_name = 'swin_large_patch4_window12_384.ms_in22k'\n",
    "\n",
    "# --- 2. ARCHITECTURE (MPS-SAFE) ---\n",
    "class ConstrainedBayarConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, padding=2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "        self.mask = torch.ones(kernel_size, kernel_size)\n",
    "        self.mask[kernel_size//2, kernel_size//2] = 0\n",
    "        self.register_buffer('filter_mask', self.mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        masked_weight = self.weight * self.filter_mask.to(x.device)\n",
    "        sum_filter = masked_weight.sum(dim=(2, 3), keepdim=True)\n",
    "        masked_weight = masked_weight / (sum_filter + 1e-7)\n",
    "        center_idx = self.kernel_size // 2\n",
    "        final_weight = masked_weight.clone()\n",
    "        final_weight[:, :, center_idx, center_idx] = -1.0\n",
    "        return F.conv2d(x, final_weight, self.bias, stride=1, padding=self.padding)\n",
    "\n",
    "class ResSobel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_x = nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.conv_y = nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False)\n",
    "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32)\n",
    "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            self.conv_x.weight.data = sobel_x.view(1, 1, 3, 3).repeat(out_channels, in_channels, 1, 1)\n",
    "            self.conv_y.weight.data = sobel_y.view(1, 1, 3, 3).repeat(out_channels, in_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gx = self.conv_x(x)\n",
    "        gy = self.conv_y(x)\n",
    "        return torch.sqrt(gx**2 + gy**2 + 1e-6)\n",
    "\n",
    "class ForensicPyramid(nn.Module):\n",
    "    def __init__(self, dim_list=[192, 384, 768]):\n",
    "        super().__init__()\n",
    "        self.bayar = ConstrainedBayarConv2d(3, 32)\n",
    "        self.sobel = ResSobel(3, 32)\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(64, dim_list[0], 3, stride=4, padding=1), nn.GroupNorm(32, dim_list[0]), nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(dim_list[0], dim_list[1], 3, stride=2, padding=1), nn.GroupNorm(32, dim_list[1]), nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(dim_list[1], dim_list[2], 3, stride=2, padding=1), nn.GroupNorm(32, dim_list[2]), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = self.bayar(x)\n",
    "        s = self.sobel(x)\n",
    "        raw = torch.cat([b, s], dim=1) \n",
    "        f1 = self.layer1(raw)\n",
    "        f2 = self.layer2(f1)\n",
    "        f3 = self.layer3(f2)\n",
    "        return f1, f2, f3\n",
    "\n",
    "class Titan_FAGT_Model(nn.Module):\n",
    "    def __init__(self, model_name=CFG.model_name):\n",
    "        super().__init__()\n",
    "        print(f\">>> Loading Backbone: {model_name}\")\n",
    "        self.swin = timm.create_model(model_name, pretrained=True, features_only=True)\n",
    "        self.swin_ch = self.swin.feature_info.channels()\n",
    "        self.forensic = ForensicPyramid(dim_list=self.swin_ch[:3])\n",
    "        self.gate1 = nn.Conv2d(self.swin_ch[0]*2, self.swin_ch[0], 1)\n",
    "        self.gate2 = nn.Conv2d(self.swin_ch[1]*2, self.swin_ch[1], 1)\n",
    "        self.gate3 = nn.Conv2d(self.swin_ch[2]*2, self.swin_ch[2], 1)\n",
    "        self.center = nn.Conv2d(self.swin_ch[-1], 512, 1)\n",
    "        self.up3 = self._up_block(512 + self.swin_ch[-2], 256)\n",
    "        self.up2 = self._up_block(256 + self.swin_ch[-3], 128)\n",
    "        self.up1 = self._up_block(128 + self.swin_ch[-4], 64)\n",
    "        self.final = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def _up_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.GroupNorm(32, out_c), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        f1, f2, f3 = self.forensic(x)\n",
    "        s_feats = self.swin(x)\n",
    "        c1, c2, c3, c4 = s_feats\n",
    "        if c4.shape[-1] == self.swin_ch[-1]:\n",
    "            c1, c2, c3, c4 = [c.permute(0, 3, 1, 2) for c in [c1, c2, c3, c4]]\n",
    "            \n",
    "        if f3.shape[2:] != c3.shape[2:]: f3 = F.interpolate(f3, size=c3.shape[2:])\n",
    "        i3 = self.gate3(torch.cat([c3, f3], dim=1))\n",
    "        \n",
    "        if f2.shape[2:] != c2.shape[2:]: f2 = F.interpolate(f2, size=c2.shape[2:])\n",
    "        i2 = self.gate2(torch.cat([c2, f2], dim=1))\n",
    "        \n",
    "        if f1.shape[2:] != c1.shape[2:]: f1 = F.interpolate(f1, size=c1.shape[2:])\n",
    "        i1 = self.gate1(torch.cat([c1, f1], dim=1))\n",
    "        \n",
    "        x = self.center(c4)\n",
    "        x = F.interpolate(x, size=i3.shape[2:], mode='bilinear')\n",
    "        x = torch.cat([x, i3], dim=1)\n",
    "        x = self.up3(x)\n",
    "        if x.shape[2:] != i2.shape[2:]: x = F.interpolate(x, size=i2.shape[2:])\n",
    "        x = torch.cat([x, i2], dim=1)\n",
    "        x = self.up2(x)\n",
    "        if x.shape[2:] != i1.shape[2:]: x = F.interpolate(x, size=i1.shape[2:])\n",
    "        x = torch.cat([x, i1], dim=1)\n",
    "        x = self.up1(x)\n",
    "        x = F.interpolate(x, size=(CFG.img_size, CFG.img_size), mode='bilinear')\n",
    "        return self.final(x)\n",
    "\n",
    "# --- 4. LOSS & UTILS ---\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "    def forward(self, inputs, targets):\n",
    "        bce = self.bce(inputs, targets)\n",
    "        inputs = torch.sigmoid(inputs).view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + 1) / (inputs.sum() + targets.sum() + 1)\n",
    "        return 0.5 * bce + 0.5 * (1 - dice)\n",
    "\n",
    "class F1ScoreMeter:\n",
    "    def __init__(self): self.tp = self.fp = self.fn = 0\n",
    "    def update(self, preds, targets):\n",
    "        preds = (torch.sigmoid(preds) > 0.5).long()\n",
    "        targets = (targets > 0.5).long()\n",
    "        self.tp += (preds * targets).sum().item()\n",
    "        self.fp += (preds * (1 - targets)).sum().item()\n",
    "        self.fn += ((1 - preds) * targets).sum().item()\n",
    "    def get_score(self):\n",
    "        prec = self.tp / (self.tp + self.fp + 1e-7)\n",
    "        rec = self.tp / (self.tp + self.fn + 1e-7)\n",
    "        f1 = 2 * prec * rec / (prec + rec + 1e-7)\n",
    "        return f1, prec, rec\n",
    "\n",
    "class TitanDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row['image_path'])\n",
    "        if img is None: img = np.zeros((384, 384, 3), dtype=np.uint8)\n",
    "        else: img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if row['label'] == 1 and row['mask_path'] and os.path.exists(row['mask_path']):\n",
    "            try:\n",
    "                m = np.load(row['mask_path'])\n",
    "                if m.ndim == 3: m = np.max(m, axis=2)\n",
    "                mask = cv2.resize((m > 0).astype(np.float32), (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            except: mask = np.zeros(img.shape[:2], dtype=np.float32)\n",
    "        else: mask = np.zeros(img.shape[:2], dtype=np.float32)\n",
    "        \n",
    "        if self.transforms:\n",
    "            aug = self.transforms(image=img, mask=mask)\n",
    "            img, mask = aug['image'], aug['mask']\n",
    "        return img, mask.unsqueeze(0)\n",
    "\n",
    "# --- 5. TRAINING LOOP ---\n",
    "def train_loop():\n",
    "    print(f\">>> TITAN V4.3: STABLE MAC TRAINING STARTED\")\n",
    "    \n",
    "    # 1. Data Prep\n",
    "    auth_files = sorted(glob.glob(os.path.join(CFG.TRAIN_IMG_PATH, 'authentic', '*.*')))\n",
    "    forg_files = sorted(glob.glob(os.path.join(CFG.TRAIN_IMG_PATH, 'forged', '*.*')))\n",
    "    print(f\">>> Found {len(auth_files)} Authentic, {len(forg_files)} Forged.\")\n",
    "    \n",
    "    data_list = []\n",
    "    for f in auth_files: data_list.append({'image_path': f, 'mask_path': None, 'label': 0})\n",
    "    for f in forg_files:\n",
    "        base = os.path.basename(f).split('.')[0]\n",
    "        m_path = os.path.join(CFG.TRAIN_MASK_PATH, base + '.npy')\n",
    "        if not os.path.exists(m_path): m_path = os.path.join(CFG.TRAIN_MASK_PATH, base + '_mask.npy')\n",
    "        data_list.append({'image_path': f, 'mask_path': m_path, 'label': 1})\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
    "    train_idx, val_idx = next(kf.split(df))\n",
    "    \n",
    "    # 2. Transforms\n",
    "    train_aug = A.Compose([\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.RandomRotate90(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    val_aug = A.Compose([\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    # 3. Loaders (NUM_WORKERS=0 FIX)\n",
    "    train_loader = DataLoader(TitanDataset(df.iloc[train_idx], train_aug), batch_size=CFG.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(TitanDataset(df.iloc[val_idx], val_aug), batch_size=CFG.batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # 4. Model\n",
    "    model = Titan_FAGT_Model().to(CFG.device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CFG.lr)\n",
    "    criterion = CombinedLoss()\n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    print(f\"\\n>>> TRAINING START ({CFG.epochs} Epochs)\")\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Clean TQDM Bar\n",
    "        pbar = tqdm(train_loader, desc=f\"Ep {epoch+1}/{CFG.epochs}\", leave=False)\n",
    "        \n",
    "        for i, (images, masks) in enumerate(pbar):\n",
    "            images, masks = images.to(CFG.device), masks.to(CFG.device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss = loss / CFG.accum_iter\n",
    "            loss.backward()\n",
    "            \n",
    "            if (i + 1) % CFG.accum_iter == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            current_loss = loss.item() * CFG.accum_iter\n",
    "            train_loss += current_loss\n",
    "            \n",
    "            # Update TQDM with loss\n",
    "            pbar.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        meter = F1ScoreMeter()\n",
    "        val_loss_sum = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(CFG.device), masks.to(CFG.device)\n",
    "                outputs = model(images)\n",
    "                val_loss_sum += criterion(outputs, masks).item()\n",
    "                meter.update(outputs, masks)\n",
    "        \n",
    "        f1, prec, rec = meter.get_score()\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss_sum / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | F1: {f1:.4f}\")\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model.state_dict(), CFG.WEIGHTS_NAME)\n",
    "            print(f\">>> SAVED BEST MODEL: {CFG.WEIGHTS_NAME}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
