{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5215c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Replicating Fold 0 Split...\n",
      ">>> Loading Weights: TITAN_V2_UNLEASHED.pth\n",
      ">>> Testing Hysteresis (High: 0.85, Low: 0.45) on 1026 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2749d57bb154345874530a9b4e0fbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1026 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " HYSTERESIS AUDIT RESULTS\n",
      "========================================\n",
      " F1 SCORE:  0.4202\n",
      " PRECISION: 0.7207\n",
      " RECALL:    0.2965\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# TITAN-FAGT V3.1: LOCAL HYSTERESIS AUDIT\n",
    "# ==================================================================================\n",
    "# 1. GOAL: Test the \"Grandmaster\" Hysteresis logic on local unseen data.\n",
    "# 2. LOGIC: High Thresh 0.85 (Seed) + Low Thresh 0.45 (Growth).\n",
    "# 3. METRIC: Calculates real F1 Score to verify if this strategy works.\n",
    "# ==================================================================================\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Safe Mode\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import gc\n",
    "import io\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import display, clear_output, Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Install timm\n",
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"timm\"])\n",
    "    import timm\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "class CFG:\n",
    "    BASE_DIR = '/Users/chanduchitikam/recodai/recodai-luc-scientific-image-forgery-detection'\n",
    "    TRAIN_IMG_PATH = os.path.join(BASE_DIR, 'train_images') \n",
    "    TRAIN_MASK_PATH = os.path.join(BASE_DIR, 'train_masks')\n",
    "    \n",
    "    # YOUR CHAMPION WEIGHTS\n",
    "    WEIGHTS_PATH = \"TITAN_V2_UNLEASHED.pth\"\n",
    "    \n",
    "    model_name = 'swin_base_patch4_window12_384'\n",
    "    img_size = 384\n",
    "    batch_size = 1\n",
    "    device = torch.device(\"mps\") \n",
    "    \n",
    "    SEED = 42\n",
    "    NUM_VISUALS = 5\n",
    "    \n",
    "    # --- HYSTERESIS SETTINGS TO TEST ---\n",
    "    HIGH_THRESH = 0.85\n",
    "    LOW_THRESH = 0.45\n",
    "    MIN_PIXELS = 50\n",
    "\n",
    "# --- 2. ARCHITECTURE ---\n",
    "class FrequencyBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "    def forward(self, x):\n",
    "        fft = torch.fft.fft2(x); fft_shift = torch.fft.fftshift(fft)\n",
    "        B, C, H, W = x.shape; cy, cx = H // 2, W // 2\n",
    "        y, x_grid = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='ij')\n",
    "        y, x_grid = y.to(x.device), x_grid.to(x.device)\n",
    "        mask = (torch.sqrt((y - cy)**2 + (x_grid - cx)**2) > 15).float().unsqueeze(0).unsqueeze(0)\n",
    "        img_back = torch.abs(torch.fft.ifft2(torch.fft.ifftshift(fft_shift * mask)))\n",
    "        return self.conv(img_back)\n",
    "\n",
    "class GraphModule(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.gcn = nn.Sequential(nn.Linear(dim, dim), nn.GELU(), nn.Linear(dim, dim))\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        nodes = x.flatten(2).transpose(1, 2)\n",
    "        q = self.proj(nodes); attn = F.softmax(torch.matmul(q, q.transpose(-2, -1)) / (C**0.5), dim=-1)\n",
    "        out = self.gcn(torch.matmul(attn, nodes))\n",
    "        return x + out.transpose(1, 2).reshape(B, C, H, W)\n",
    "\n",
    "class FAGT_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(CFG.model_name, pretrained=False, features_only=True)\n",
    "        self.dims = self.encoder.feature_info.channels()\n",
    "        last_dim = self.dims[-1]\n",
    "        self.physics = FrequencyBlock(); self.graph = GraphModule(last_dim)\n",
    "        self.fusion = nn.Conv2d(last_dim + 32, 256, 1)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(128, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(64, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(32, 1, 1))\n",
    "    def forward(self, x):\n",
    "        enc_feats = self.encoder(x); deep_feats = enc_feats[-1]\n",
    "        if deep_feats.ndim == 4 and deep_feats.shape[-1] == self.dims[-1]: deep_feats = deep_feats.permute(0, 3, 1, 2)\n",
    "        phys_feats = self.physics(x); graph_feats = self.graph(deep_feats)\n",
    "        phys_resized = F.interpolate(phys_feats, size=graph_feats.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        fused = self.fusion(torch.cat([graph_feats, phys_resized], dim=1))\n",
    "        return F.interpolate(self.decoder(fused), size=x.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "# --- 3. HYSTERESIS LOGIC ---\n",
    "def apply_hysteresis(prob_map, high, low, min_size):\n",
    "    h, w = prob_map.shape\n",
    "    strong_mask = (prob_map >= high).astype(np.uint8)\n",
    "    weak_mask = (prob_map >= low).astype(np.uint8)\n",
    "    \n",
    "    # Fast Fail: If no strong seed, return all black\n",
    "    if strong_mask.sum() < min_size:\n",
    "        return np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    # Grow Weak regions that touch Strong regions\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(weak_mask, connectivity=8)\n",
    "    final_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(1, num_labels):\n",
    "        blob_mask = (labels == i).astype(np.uint8)\n",
    "        # If overlap with strong mask, keep the blob\n",
    "        if cv2.bitwise_and(blob_mask, strong_mask).sum() > 0:\n",
    "            final_mask = cv2.bitwise_or(final_mask, blob_mask)\n",
    "            \n",
    "    return final_mask\n",
    "\n",
    "# --- 4. DATA SETUP ---\n",
    "def get_validation_data():\n",
    "    print(\">>> Replicating Fold 0 Split...\")\n",
    "    auth = sorted(glob.glob(f'{CFG.TRAIN_IMG_PATH}/authentic/*.*'))\n",
    "    forg = sorted(glob.glob(f'{CFG.TRAIN_IMG_PATH}/forged/*.*'))\n",
    "    data = [{'image_path': f, 'mask_path': None, 'label': 0} for f in auth]\n",
    "    for f in forg:\n",
    "        base = os.path.basename(f).split('.')[0]\n",
    "        mp = f'{CFG.TRAIN_MASK_PATH}/{base}.npy'\n",
    "        if not os.path.exists(mp): mp = f'{CFG.TRAIN_MASK_PATH}/{base}_mask.npy'\n",
    "        data.append({'image_path': f, 'mask_path': mp, 'label': 1})\n",
    "    df = pd.DataFrame(data)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=CFG.SEED)\n",
    "    _, val_idx = next(kf.split(df))\n",
    "    return df.iloc[val_idx].copy()\n",
    "\n",
    "def visualize_result(img_tensor, mask_tensor, pred_mask, fname):\n",
    "    mean, std = np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225])\n",
    "    img_np = np.clip(img_tensor.detach().cpu().permute(1,2,0).numpy()*std+mean, 0, 1)\n",
    "    mask_np = mask_tensor.detach().cpu().squeeze().numpy()\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5), facecolor='#0f0f0f')\n",
    "    gs = gridspec.GridSpec(1, 3)\n",
    "    \n",
    "    p1 = fig.add_subplot(gs[0, 0]); p1.imshow(img_np); p1.axis('off'); p1.set_title(f\"SOURCE: {fname}\", color='white')\n",
    "    p2 = fig.add_subplot(gs[0, 1]); p2.imshow(mask_np, cmap='gray'); p2.axis('off'); p2.set_title(\"TRUTH\", color='white')\n",
    "    p3 = fig.add_subplot(gs[0, 2]); p3.imshow(pred_mask, cmap='jet', vmin=0, vmax=1); p3.axis('off'); p3.set_title(\"HYSTERESIS PRED\", color='white')\n",
    "    \n",
    "    plt.tight_layout(); display(fig); plt.close(fig); gc.collect()\n",
    "\n",
    "# --- 5. EXECUTION ---\n",
    "def run_local_audit():\n",
    "    val_df = get_validation_data()\n",
    "    print(f\">>> Loading Weights: {CFG.WEIGHTS_PATH}\")\n",
    "    model = FAGT_Model().to(CFG.device)\n",
    "    if os.path.exists(CFG.WEIGHTS_PATH): model.load_state_dict(torch.load(CFG.WEIGHTS_PATH, map_location=CFG.device))\n",
    "    else: print(\"!!! CRITICAL: Weights missing.\"); return\n",
    "    model.eval()\n",
    "    \n",
    "    class AuditDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, df): self.df = df; self.tf = A.Compose([A.Resize(CFG.img_size, CFG.img_size), A.Normalize(), ToTensorV2()])\n",
    "        def __len__(self): return len(self.df)\n",
    "        def __getitem__(self, idx):\n",
    "            row = self.df.iloc[idx]; img = cv2.imread(row['image_path'])\n",
    "            if img is None: img = np.zeros((384,384,3), dtype=np.uint8)\n",
    "            else: img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            mask = np.zeros(img.shape[:2], dtype=np.float32)\n",
    "            if row['label']==1 and row['mask_path']:\n",
    "                try: \n",
    "                    m=np.load(row['mask_path'])\n",
    "                    if m.ndim==3: m=m.max(axis=2)\n",
    "                    mask = cv2.resize((m>0).astype(np.float32), (img.shape[1], img.shape[0]), interpolation=0)\n",
    "                except: pass\n",
    "            aug = self.tf(image=img, mask=mask)\n",
    "            return aug['image'], aug['mask'].unsqueeze(0), row['image_path']\n",
    "\n",
    "    dl = torch.utils.data.DataLoader(AuditDataset(val_df), batch_size=1, shuffle=False)\n",
    "    print(f\">>> Testing Hysteresis (High: {CFG.HIGH_THRESH}, Low: {CFG.LOW_THRESH}) on {len(dl)} images...\")\n",
    "    \n",
    "    all_preds, all_gts = [], []\n",
    "    visual_indices = sorted(random.sample(range(len(dl)), min(len(dl), CFG.NUM_VISUALS)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, msk, path) in enumerate(tqdm(dl)):\n",
    "            img, msk = img.to(CFG.device), msk.to(CFG.device)\n",
    "            \n",
    "            # TTA: Base + Flip\n",
    "            p1 = torch.sigmoid(model(img))[0,0]\n",
    "            p2 = torch.flip(torch.sigmoid(model(torch.flip(img, [3]))), [3])[0,0]\n",
    "            prob_map = ((p1 + p2) / 2.0).cpu().numpy()\n",
    "            \n",
    "            # --- APPLY HYSTERESIS ---\n",
    "            final_mask = apply_hysteresis(prob_map, CFG.HIGH_THRESH, CFG.LOW_THRESH, CFG.MIN_PIXELS)\n",
    "            \n",
    "            # Save for Stats\n",
    "            all_preds.append(final_mask.flatten())\n",
    "            all_gts.append(msk.cpu().numpy().flatten().astype(np.uint8))\n",
    "            \n",
    "            if i in visual_indices: \n",
    "                visualize_result(img[0], msk[0], final_mask, os.path.basename(path[0]))\n",
    "\n",
    "    # Stats\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_gts)\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=1)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\" HYSTERESIS AUDIT RESULTS\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\" F1 SCORE:  {f1:.4f}\")\n",
    "    print(f\" PRECISION: {prec:.4f}\")\n",
    "    print(f\" RECALL:    {rec:.4f}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_local_audit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
