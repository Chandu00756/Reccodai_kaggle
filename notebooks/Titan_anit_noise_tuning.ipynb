{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee32498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> TITAN V5: MORPHOLOGICAL CLEANING INFERENCE...\n",
      ">>> Loading V2.5 Swin Model: /kaggle/input/recodai-model/TITAN_V2_UNLEASHED.pth\n",
      "!!! CRITICAL: Weights not found.\n",
      ">>> Processing 0 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3df145968f4e8f87c5198394db0d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SUCCESS: Submission Saved. Rows: 1\n",
      "  case_id annotation\n",
      "0      45  authentic\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "# TITAN V5: MORPHOLOGICAL CLEANING (The \"Cyan Fog\" Killer)\n",
    "# ==================================================================================\n",
    "# 1. MODEL: Uses TITAN V2.5 (Swin) because it had the best F1 (0.56).\n",
    "# 2. FIX: Applies \"Morphological Opening\" to physically erase noise.\n",
    "#    - Step A: Erosion (Shrinks bright spots, killing small noise).\n",
    "#    - Step B: Dilation (Grows the remaining big spots back to original size).\n",
    "# 3. RESULT: Keeps the big forgeries, deletes the \"fog\" that ruins the score.\n",
    "# ==================================================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "# Offline IMM Check\n",
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "    import timm\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "class CFG:\n",
    "    TEST_DIR = '/kaggle/input/recodai-luc-scientific-image-forgery-detection/test_images'\n",
    "    SAMPLE_SUB = '/kaggle/input/recodai-luc-scientific-image-forgery-detection/sample_submission.csv'\n",
    "    \n",
    "    # !!! IMPORTANT: USE THE V2.5 WEIGHTS (The ones that scored 0.56) !!!\n",
    "    WEIGHTS_PATH = '/kaggle/input/recodai-model/TITAN_V2_UNLEASHED.pth'\n",
    "    \n",
    "    model_name = 'swin_base_patch4_window12_384'\n",
    "    img_size = 384\n",
    "    batch_size = 1\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # --- CLEANING SETTINGS ---\n",
    "    # We use a lower threshold because we trust the Morphological Cleaner to remove noise.\n",
    "    THRESHOLD = 0.50       # Standard threshold (trust the model's 0.56 logic)\n",
    "    MIN_PIXELS = 200       # Minimum size AFTER cleaning\n",
    "    KERNEL_SIZE = 3        # Size of the \"Eraser\" (3x3 pixels)\n",
    "\n",
    "# --- 2. ARCHITECTURE (Must match V2.5 Swin) ---\n",
    "class FrequencyBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "    def forward(self, x):\n",
    "        fft = torch.fft.fft2(x); fft_shift = torch.fft.fftshift(fft)\n",
    "        B, C, H, W = x.shape; cy, cx = H // 2, W // 2\n",
    "        y, x_grid = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='ij')\n",
    "        y, x_grid = y.to(x.device), x_grid.to(x.device)\n",
    "        mask = (torch.sqrt((y - cy)**2 + (x_grid - cx)**2) > 15).float().unsqueeze(0).unsqueeze(0)\n",
    "        img_back = torch.abs(torch.fft.ifft2(torch.fft.ifftshift(fft_shift * mask)))\n",
    "        return self.conv(img_back)\n",
    "\n",
    "class GraphModule(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.gcn = nn.Sequential(nn.Linear(dim, dim), nn.GELU(), nn.Linear(dim, dim))\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        nodes = x.flatten(2).transpose(1, 2)\n",
    "        q = self.proj(nodes); attn = F.softmax(torch.matmul(q, q.transpose(-2, -1)) / (C**0.5), dim=-1)\n",
    "        out = self.gcn(torch.matmul(attn, nodes))\n",
    "        return x + out.transpose(1, 2).reshape(B, C, H, W)\n",
    "\n",
    "class FAGT_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(CFG.model_name, pretrained=False, features_only=True)\n",
    "        self.dims = self.encoder.feature_info.channels()\n",
    "        last_dim = self.dims[-1]\n",
    "        self.physics = FrequencyBlock(); self.graph = GraphModule(last_dim)\n",
    "        self.fusion = nn.Conv2d(last_dim + 32, 256, 1)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(128, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(64, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(32, 1, 1))\n",
    "    def forward(self, x):\n",
    "        enc_feats = self.encoder(x); deep_feats = enc_feats[-1]\n",
    "        if deep_feats.ndim == 4 and deep_feats.shape[-1] == self.dims[-1]: deep_feats = deep_feats.permute(0, 3, 1, 2)\n",
    "        phys_feats = self.physics(x); graph_feats = self.graph(deep_feats)\n",
    "        phys_resized = F.interpolate(phys_feats, size=graph_feats.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        fused = self.fusion(torch.cat([graph_feats, phys_resized], dim=1))\n",
    "        return F.interpolate(self.decoder(fused), size=x.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "# --- 3. HELPER FUNCTIONS ---\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return json.dumps([int(x) for x in runs])\n",
    "\n",
    "def apply_morphological_cleaning(prob_map, threshold=0.5, min_pixels=200):\n",
    "    \"\"\"\n",
    "    Standard Morphological Opening to remove noise.\n",
    "    1. Threshold\n",
    "    2. Erode (Shrink) -> Kills small noise\n",
    "    3. Dilate (Expand) -> Restores size of real objects\n",
    "    \"\"\"\n",
    "    h, w = prob_map.shape\n",
    "    \n",
    "    # 1. Binary Threshold\n",
    "    mask = (prob_map > threshold).astype(np.uint8)\n",
    "    \n",
    "    # 2. Define Kernel (The \"Eraser\")\n",
    "    # A 3x3 kernel looks at neighbors. If neighbors are 0, it kills the pixel.\n",
    "    kernel = np.ones((CFG.KERNEL_SIZE, CFG.KERNEL_SIZE), np.uint8)\n",
    "    \n",
    "    # 3. Morphological Opening (Erosion followed by Dilation)\n",
    "    # This is the standard CV way to remove \"salt\" noise.\n",
    "    clean_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # 4. Final Size Check (Safety)\n",
    "    if clean_mask.sum() < min_pixels:\n",
    "        return np.zeros((h, w), dtype=np.uint8)\n",
    "        \n",
    "    return clean_mask\n",
    "\n",
    "def load_model(path):\n",
    "    print(f\">>> Loading V2.5 Swin Model: {path}\")\n",
    "    model = FAGT_Model()\n",
    "    if os.path.exists(path):\n",
    "        state = torch.load(path, map_location=CFG.device)\n",
    "        model.load_state_dict(state, strict=True)\n",
    "        print(\">>> Weights Loaded Successfully.\")\n",
    "    else:\n",
    "        print(\"!!! CRITICAL: Weights not found.\")\n",
    "    model.to(CFG.device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# --- 4. EXECUTION ---\n",
    "def run_inference():\n",
    "    print(\">>> TITAN V5: MORPHOLOGICAL CLEANING INFERENCE...\")\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(CFG.TEST_DIR, '**', '*'), recursive=True)\n",
    "    id_map = {}\n",
    "    for f in all_files:\n",
    "        ext = os.path.splitext(f)[1].lower()\n",
    "        if ext in ['.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp']:\n",
    "            base = os.path.basename(f)\n",
    "            digits = ''.join(filter(str.isdigit, os.path.splitext(base)[0]))\n",
    "            if digits: id_map[str(int(digits))] = f \n",
    "\n",
    "    model = load_model(CFG.WEIGHTS_PATH)\n",
    "    transform = A.Compose([\n",
    "        A.Resize(CFG.img_size, CFG.img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()])\n",
    "\n",
    "    preds_list = []\n",
    "    print(f\">>> Processing {len(id_map)} images...\")\n",
    "    \n",
    "    for case_id, path in tqdm(id_map.items()):\n",
    "        label = \"authentic\"\n",
    "        try:\n",
    "            image = cv2.imread(path)\n",
    "            if image is None: image = np.array(Image.open(path).convert('RGB'))\n",
    "            else: image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            h, w = image.shape[:2]\n",
    "            \n",
    "            # TTA: Simple Flip\n",
    "            img_t = transform(image=image)['image'].unsqueeze(0).to(CFG.device)\n",
    "            with torch.no_grad():\n",
    "                p1 = torch.sigmoid(model(img_t))[0,0]\n",
    "                p2 = torch.flip(torch.sigmoid(model(torch.flip(img_t, [3]))), [3])[0,0]\n",
    "                prob_map = ((p1 + p2) / 2.0).cpu().numpy()\n",
    "            \n",
    "            # Resize\n",
    "            pred_full = cv2.resize(prob_map, (w, h))\n",
    "            \n",
    "            # --- APPLY MORPHOLOGICAL CLEANING ---\n",
    "            # This is cleaner and faster than Hysteresis\n",
    "            mask = apply_morphological_cleaning(\n",
    "                pred_full, \n",
    "                threshold=CFG.THRESHOLD, \n",
    "                min_pixels=CFG.MIN_PIXELS\n",
    "            )\n",
    "            \n",
    "            if mask.sum() > 0:\n",
    "                label = rle_encode(mask)\n",
    "                if label == \"\": label = \"authentic\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            pass \n",
    "            \n",
    "        preds_list.append({\"case_id\": case_id, \"annotation\": label})\n",
    "\n",
    "    try:\n",
    "        sample_sub = pd.read_csv(CFG.SAMPLE_SUB)\n",
    "    except:\n",
    "        sample_sub = pd.DataFrame({'case_id': [45], 'annotation': ['authentic']})\n",
    "        \n",
    "    sample_sub['case_id'] = sample_sub['case_id'].astype(str)\n",
    "    \n",
    "    if len(preds_list) > 0:\n",
    "        preds_df = pd.DataFrame(preds_list)\n",
    "        preds_df['case_id'] = preds_df['case_id'].astype(str)\n",
    "        submission = sample_sub[['case_id']].merge(preds_df, on='case_id', how='left')\n",
    "        submission['annotation'] = submission['annotation'].fillna(\"authentic\")\n",
    "    else:\n",
    "        submission = sample_sub\n",
    "        submission['annotation'] = 'authentic'\n",
    "\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(f\">>> SUCCESS: Submission Saved. Rows: {len(submission)}\")\n",
    "    print(submission.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
