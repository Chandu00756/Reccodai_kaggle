{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================\n",
    "# TITAN-FAGT: LOCAL END-TO-END VALIDATOR (Mac Edition)\n",
    "# ==================================================================================\n",
    "# 1. GOAL: Calculate F1, Precision, and Recall on unseen LOCAL training data.\n",
    "# 2. DATA: Matches 'train_images' with corresponding 'train_masks' (.npy).\n",
    "# 3. FIX: Restored missing BASE_PATH and path recursion logic.\n",
    "# ==================================================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "# Offline TIMM Check\n",
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    import sys\n",
    "    sys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "    import timm\n",
    "\n",
    "class CFG:\n",
    "    # --- PATHS (Adjusted for your local folder tree) ---\n",
    "    BASE_PATH = './recodai-luc-scientific-image-forgery-detection'\n",
    "    IMG_DIR = os.path.join(BASE_PATH, 'train_images')\n",
    "    MASK_DIR = os.path.join(BASE_PATH, 'train_masks')\n",
    "    WEIGHTS_PATH = './TITAN_V2_UNLEASHED.pth'\n",
    "    \n",
    "    img_size = 384\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    THRESHOLD = 0.50 \n",
    "\n",
    "# --- 2. ARCHITECTURE ---\n",
    "class FrequencyBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "    def forward(self, x):\n",
    "        fft = torch.fft.fft2(x); fft_shift = torch.fft.fftshift(fft)\n",
    "        B, C, H, W = x.shape; cy, cx = H // 2, W // 2\n",
    "        y, x_grid = torch.meshgrid(torch.arange(H), torch.arange(W), indexing='ij')\n",
    "        y, x_grid = y.to(x.device), x_grid.to(x.device)\n",
    "        mask = (torch.sqrt((y - cy)**2 + (x_grid - cx)**2) > 15).float().unsqueeze(0).unsqueeze(0)\n",
    "        img_back = torch.abs(torch.fft.ifft2(torch.fft.ifftshift(fft_shift * mask)))\n",
    "        return self.conv(img_back)\n",
    "\n",
    "class GraphModule(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.gcn = nn.Sequential(nn.Linear(dim, dim), nn.GELU(), nn.Linear(dim, dim))\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        nodes = x.flatten(2).transpose(1, 2)\n",
    "        q = self.proj(nodes); attn = F.softmax(torch.matmul(q, q.transpose(-2, -1)) / (C**0.5), dim=-1)\n",
    "        out = self.gcn(torch.matmul(attn, nodes))\n",
    "        return x + out.transpose(1, 2).reshape(B, C, H, W)\n",
    "\n",
    "class FAGT_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(CFG.model_name if hasattr(CFG, 'model_name') else 'swin_base_patch4_window12_384', pretrained=False, features_only=True)\n",
    "        self.dims = self.encoder.feature_info.channels()\n",
    "        last_dim = self.dims[-1]\n",
    "        self.physics = FrequencyBlock(); self.graph = GraphModule(last_dim)\n",
    "        self.fusion = nn.Conv2d(last_dim + 32, 256, 1)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(128, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(64, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(32, 1, 1))\n",
    "    def forward(self, x):\n",
    "        enc_feats = self.encoder(x); deep_feats = enc_feats[-1]\n",
    "        if deep_feats.ndim == 4 and deep_feats.shape[-1] == self.dims[-1]: deep_feats = deep_feats.permute(0, 3, 1, 2)\n",
    "        phys_feats = self.physics(x); graph_feats = self.graph(deep_feats)\n",
    "        phys_resized = F.interpolate(phys_feats, size=graph_feats.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        fused = self.fusion(torch.cat([graph_feats, phys_resized], dim=1))\n",
    "        return F.interpolate(self.decoder(fused), size=x.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "# --- 3. METRIC HELPERS ---\n",
    "def calculate_pixel_stats(pred_mask, gt_mask):\n",
    "    pred = (pred_mask > CFG.THRESHOLD).astype(np.uint8)\n",
    "    gt = (gt_mask > 0).astype(np.uint8)\n",
    "    tp = np.sum((pred == 1) & (gt == 1))\n",
    "    fp = np.sum((pred == 1) & (gt == 0))\n",
    "    fn = np.sum((pred == 0) & (gt == 1))\n",
    "    return tp, fp, fn\n",
    "\n",
    "# --- 4. EXECUTION ---\n",
    "def run_local_test():\n",
    "    print(f\">>> RUNNING VALIDATOR ON: {CFG.device}\")\n",
    "    \n",
    "    # Correct recursion to find images in subfolders\n",
    "    img_paths = glob.glob(os.path.join(CFG.IMG_DIR, '**', '*.*'), recursive=True)\n",
    "    img_paths = [p for p in img_paths if p.lower().endswith(('.png', '.jpg', '.jpeg', '.tif'))]\n",
    "    \n",
    "    if not img_paths:\n",
    "        print(f\"!!! ERROR: No images found in {CFG.IMG_DIR}\")\n",
    "        return\n",
    "\n",
    "    model = FAGT_Model()\n",
    "    if os.path.exists(CFG.WEIGHTS_PATH):\n",
    "        model.load_state_dict(torch.load(CFG.WEIGHTS_PATH, map_location=CFG.device))\n",
    "        print(f\">>> Weights Loaded: {CFG.WEIGHTS_PATH}\")\n",
    "    else:\n",
    "        print(f\"!!! CRITICAL: Weights missing at {CFG.WEIGHTS_PATH}\")\n",
    "        return\n",
    "    model.to(CFG.device).eval()\n",
    "\n",
    "    transform = A.Compose([A.Resize(CFG.img_size, CFG.img_size), A.Normalize(), ToTensorV2()])\n",
    "\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "    results = []\n",
    "\n",
    "    for path in tqdm(img_paths):\n",
    "        base = os.path.basename(path).split('.')[0]\n",
    "        mask_path = os.path.join(CFG.MASK_DIR, f\"{base}.npy\")\n",
    "        if not os.path.exists(mask_path): mask_path = os.path.join(CFG.MASK_DIR, f\"{base}_mask.npy\")\n",
    "        if not os.path.exists(mask_path): continue\n",
    "\n",
    "        # 1. Load Data\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w = image.shape[:2]\n",
    "        gt_mask = np.load(mask_path)\n",
    "        if gt_mask.ndim == 3: gt_mask = gt_mask.max(axis=2)\n",
    "        gt_mask = cv2.resize((gt_mask > 0).astype(np.float32), (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # 2. Inference\n",
    "        img_t = transform(image=image)['image'].unsqueeze(0).to(CFG.device)\n",
    "        with torch.no_grad():\n",
    "            pred = torch.sigmoid(model(img_t)).cpu().numpy().squeeze()\n",
    "        pred_full = cv2.resize(pred, (w, h))\n",
    "\n",
    "        # 3. Calculate Stats\n",
    "        tp, fp, fn = calculate_pixel_stats(pred_full, gt_mask)\n",
    "        total_tp += tp; total_fp += fp; total_fn += fn\n",
    "        \n",
    "        # Live feedback like Kaggle script\n",
    "        img_f1 = (2*tp)/(2*tp + fp + fn + 1e-7)\n",
    "        print(f\"  [+] {base}: Pixel F1 {img_f1:.4f} | Max Prob: {np.max(pred):.4f}\")\n",
    "        results.append({\"case_id\": base, \"f1\": img_f1, \"max_prob\": np.max(pred)})\n",
    "\n",
    "    if not results:\n",
    "        print(\">>> No matching images and masks found.\")\n",
    "        return\n",
    "\n",
    "    # Final Summary\n",
    "    precision = total_tp / (total_tp + total_fp + 1e-7)\n",
    "    recall = total_tp / (total_tp + total_fn + 1e-7)\n",
    "    final_f1 = (2 * precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"FINAL LOCAL PERFORMANCE (Unseen Data):\")\n",
    "    print(f\"PRECISION: {precision:.4f}\")\n",
    "    print(f\"RECALL:    {recall:.4f}\")\n",
    "    print(f\"F1-SCORE:  {final_f1:.4f}\")\n",
    "    print(\"=\"*40)\n",
    "    pd.DataFrame(results).to_csv(\"local_test_results.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_local_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
